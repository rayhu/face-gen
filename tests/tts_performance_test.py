#!/usr/bin/env python3
"""
Tortoise TTS æ€§èƒ½æµ‹è¯•
ä¸“é—¨æµ‹è¯• TTS ä»»åŠ¡ä¸­ MPS å’Œ CPU çš„æ€§èƒ½å·®å¼‚
"""

import torch
import time
import os
from tortoise.api import TextToSpeech

def test_tts_performance():
    """æµ‹è¯• TTS æ€§èƒ½"""
    print("ğŸ¤ Tortoise TTS æ€§èƒ½æµ‹è¯•")
    print("=" * 40)
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚",
        "è¿™æ˜¯ä¸€ä¸ªè¾ƒé•¿çš„æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯• TTS çš„æ€§èƒ½è¡¨ç°ã€‚",
        "è¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„æµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«äº†æ›´å¤šçš„å†…å®¹ï¼Œç”¨äºæµ‹è¯•åœ¨ä¸åŒæ–‡æœ¬é•¿åº¦ä¸‹ TTS çš„æ€§èƒ½è¡¨ç°ã€‚",
        "è¿™æ˜¯ä¸€ä¸ªè¶…é•¿çš„æµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«äº†å¤§é‡çš„å†…å®¹ï¼Œç”¨äºæµ‹è¯•åœ¨æœ€å¤§æ–‡æœ¬é•¿åº¦ä¸‹ TTS çš„æ€§èƒ½è¡¨ç°ï¼Œçœ‹çœ‹ MPS å’Œ CPU çš„å·®å¼‚ã€‚"
    ]
    
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("audio", exist_ok=True)
    
    for i, text in enumerate(test_texts):
        print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬ {i+1} (é•¿åº¦: {len(text)} å­—ç¬¦)")
        print(f"æ–‡æœ¬å†…å®¹: {text[:50]}{'...' if len(text) > 50 else ''}")
        
        # CPU æµ‹è¯•
        print("  ğŸ’» CPU æµ‹è¯•...")
        try:
            tts_cpu = TextToSpeech()
            start_time = time.time()
            gen_audio_cpu = tts_cpu.tts(text)
            cpu_time = time.time() - start_time
            
            # ä¿å­˜ CPU ç»“æœ
            torchaudio.save(f"audio/cpu_test_{i+1}.wav", gen_audio_cpu.squeeze(0), 24000)
            cpu_file_size = os.path.getsize(f"audio/cpu_test_{i+1}.wav")
            
            print(f"    CPU è€—æ—¶: {cpu_time:.2f}ç§’")
            print(f"    CPU æ–‡ä»¶å¤§å°: {cpu_file_size} bytes")
            
        except Exception as e:
            print(f"    âŒ CPU æµ‹è¯•å¤±è´¥: {str(e)}")
            cpu_time = float('inf')
            cpu_file_size = 0
        
        # MPS æµ‹è¯•
        print("  ğŸš€ MPS æµ‹è¯•...")
        try:
            tts_mps = TextToSpeech()
            
            # ç§»åŠ¨æ¨¡å‹åˆ° MPS
            if device.type == "mps":
                if hasattr(tts_mps, 'autoregressive'):
                    tts_mps.autoregressive = tts_mps.autoregressive.to(device)
                if hasattr(tts_mps, 'diffusion'):
                    tts_mps.diffusion = tts_mps.diffusion.to(device)
                if hasattr(tts_mps, 'vocoder'):
                    tts_mps.vocoder = tts_mps.vocoder.to(device)
                if hasattr(tts_mps, 'clvp'):
                    tts_mps.clvp = tts_mps.clvp.to(device)
            
            start_time = time.time()
            gen_audio_mps = tts_mps.tts(text)
            mps_time = time.time() - start_time
            
            # å°†éŸ³é¢‘ç§»å› CPU å¹¶ä¿å­˜
            if device.type == "mps":
                gen_audio_mps = gen_audio_mps.cpu()
            
            torchaudio.save(f"audio/mps_test_{i+1}.wav", gen_audio_mps.squeeze(0), 24000)
            mps_file_size = os.path.getsize(f"audio/mps_test_{i+1}.wav")
            
            print(f"    MPS è€—æ—¶: {mps_time:.2f}ç§’")
            print(f"    MPS æ–‡ä»¶å¤§å°: {mps_file_size} bytes")
            
        except Exception as e:
            print(f"    âŒ MPS æµ‹è¯•å¤±è´¥: {str(e)}")
            mps_time = float('inf')
            mps_file_size = 0
        
        # æ€§èƒ½æ¯”è¾ƒ
        if cpu_time != float('inf') and mps_time != float('inf'):
            speedup = cpu_time / mps_time
            print(f"  âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
            
            if speedup > 1:
                print(f"  âœ… MPS æ›´å¿«")
            else:
                print(f"  âš ï¸  CPU æ›´å¿«")
        else:
            print(f"  âŒ æ— æ³•æ¯”è¾ƒæ€§èƒ½")

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½æ€§èƒ½"""
    print("\nğŸ“¦ æ¨¡å‹åŠ è½½æ€§èƒ½æµ‹è¯•")
    print("=" * 40)
    
    # CPU æ¨¡å‹åŠ è½½
    print("ğŸ’» CPU æ¨¡å‹åŠ è½½...")
    start_time = time.time()
    tts_cpu = TextToSpeech()
    cpu_load_time = time.time() - start_time
    print(f"  CPU åŠ è½½è€—æ—¶: {cpu_load_time:.2f}ç§’")
    
    # MPS æ¨¡å‹åŠ è½½
    print("ğŸš€ MPS æ¨¡å‹åŠ è½½...")
    start_time = time.time()
    tts_mps = TextToSpeech()
    
    # ç§»åŠ¨æ¨¡å‹åˆ° MPS
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    if device.type == "mps":
        if hasattr(tts_mps, 'autoregressive'):
            tts_mps.autoregressive = tts_mps.autoregressive.to(device)
        if hasattr(tts_mps, 'diffusion'):
            tts_mps.diffusion = tts_mps.diffusion.to(device)
        if hasattr(tts_mps, 'vocoder'):
            tts_mps.vocoder = tts_mps.vocoder.to(device)
        if hasattr(tts_mps, 'clvp'):
            tts_mps.clvp = tts_mps.clvp.to(device)
    
    mps_load_time = time.time() - start_time
    print(f"  MPS åŠ è½½è€—æ—¶: {mps_load_time:.2f}ç§’")
    
    # æ¯”è¾ƒåŠ è½½æ—¶é—´
    load_speedup = cpu_load_time / mps_load_time
    print(f"  âš¡ åŠ è½½åŠ é€Ÿæ¯”: {load_speedup:.2f}x")

def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
    test_files = [
        "audio/cpu_test_1.wav",
        "audio/cpu_test_2.wav", 
        "audio/cpu_test_3.wav",
        "audio/cpu_test_4.wav",
        "audio/mps_test_1.wav",
        "audio/mps_test_2.wav",
        "audio/mps_test_3.wav",
        "audio/mps_test_4.wav"
    ]
    
    for file in test_files:
        if os.path.exists(file):
            os.remove(file)
            print(f"  âœ… å·²åˆ é™¤: {file}")

if __name__ == "__main__":
    print("ğŸ¯ Tortoise TTS æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
    
    # è¿è¡Œæµ‹è¯•
    test_model_loading()
    test_tts_performance()
    
    print("\nğŸ“Š æ€§èƒ½æ€»ç»“:")
    print("  - å¯¹äº Tortoise TTS ä»»åŠ¡ï¼Œæ€§èƒ½å·®å¼‚ä¸»è¦å–å†³äº:")
    print("    1. æ–‡æœ¬é•¿åº¦")
    print("    2. æ¨¡å‹å¤§å°")
    print("    3. æ•°æ®ä¼ è¾“å¼€é”€")
    print("    4. å†…å­˜ä½¿ç”¨æƒ…å†µ")
    
    # æ¸…ç†æ–‡ä»¶
    cleanup_test_files()
    
    print("\nğŸ‰ TTS æ€§èƒ½æµ‹è¯•å®Œæˆï¼") 